import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import { getAnalysisConfig } from '../../lib/prompts';

// Tipo para la configuraci√≥n (actualizado para compatibilidad)
export interface AnalysisConfig {
  settings: {
    openai: {
      model: string;
      temperature: number;
      maxTokens: number;
    };
    analysis: {
      minPromptLength: number;
      maxTopDimensions: number;
      responseLanguage: string;
    };
  };
  systemPrompt: {
    content: string;
  };
  dimensions: Array<{
    id: string;
    name: string;
    description: string;
    category: string;
    keywords: string[];
  }>;
  responseFormat: {
    schema: any;
  };
}

// Funci√≥n para cargar la configuraci√≥n desde prompts.json
async function loadAnalysisConfig(): Promise<AnalysisConfig> {
  try {
    const config = await getAnalysisConfig();
    
    console.log('üìã [CONFIG] Configuraci√≥n cargada exitosamente desde prompts.json');
    console.log('üìä [CONFIG] Dimensiones disponibles:', config.dimensions.length);
    console.log('ü§ñ [CONFIG] Modelo:', config.settings.openai.model);
    
    return {
      settings: config.settings,
      systemPrompt: config.systemPrompt,
      dimensions: config.dimensions,
      responseFormat: {
        schema: {
          type: "object",
          properties: {
            dimensions: {
              type: "object",
              description: "Porcentajes de 0-100 para cada dimensi√≥n"
            },
            topDimensions: {
              type: "array",
              description: "Array con las 3-5 dimensiones m√°s altas con reasoning"
            }
          }
        }
      }
    };
  } catch (error: any) {
    console.error('‚ùå [CONFIG] Error cargando configuraci√≥n:', error.message);
    throw new Error(`No se pudo cargar la configuraci√≥n: ${error.message}`);
  }
}

// Funci√≥n para validar el an√°lisis seg√∫n la configuraci√≥n
function validateAnalysisResult(result: any, config: AnalysisConfig): any {
  console.log('üîç [VALIDATION] Iniciando validaci√≥n del resultado...');
  
  if (!result || typeof result !== 'object') {
    throw new Error('Formato de respuesta incorrecto: no es un objeto');
  }

  if (!result.dimensions || typeof result.dimensions !== 'object') {
    throw new Error('Formato de respuesta incorrecto: falta dimensions');
  }

  if (!result.topDimensions || !Array.isArray(result.topDimensions)) {
    throw new Error('Formato de respuesta incorrecto: falta topDimensions');
  }

  // Validar que todas las dimensiones esperadas est√©n presentes
  const expectedDimensions = config.dimensions.map(d => d.id);
  const missingDimensions = expectedDimensions.filter(dim => 
    !(dim in result.dimensions) || 
    typeof result.dimensions[dim] !== 'number'
  );

  if (missingDimensions.length > 0) {
    console.log('‚ö†Ô∏è [VALIDATION] Dimensiones faltantes:', missingDimensions);
    // A√±adir dimensiones faltantes con valor por defecto
    missingDimensions.forEach(dim => {
      result.dimensions[dim] = 0;
    });
  }

  // Validar topDimensions
  if (result.topDimensions.length === 0) {
    console.log('‚ö†Ô∏è [VALIDATION] No hay topDimensions, generando autom√°ticamente');
    // Generar topDimensions desde dimensions si est√° vac√≠o
    const sortedDimensions = Object.entries(result.dimensions)
      .sort(([,a], [,b]) => (b as number) - (a as number))
      .slice(0, config.settings.analysis.maxTopDimensions)
      .map(([dimensionId, percentage]) => {
        const dimensionConfig = config.dimensions.find(d => d.id === dimensionId);
        return {
          name: dimensionId,
          label: dimensionConfig?.name || dimensionId,
          percentage: percentage as number,
          reasoning: "Dimensi√≥n identificada autom√°ticamente por el an√°lisis"
        };
      });
    
    result.topDimensions = sortedDimensions;
  }

  // Asegurar que los labels de topDimensions correspondan a los nombres configurados
  result.topDimensions = result.topDimensions.map((topDim: any) => {
    const dimensionConfig = config.dimensions.find(d => d.id === topDim.name);
    return {
      ...topDim,
      label: dimensionConfig?.name || topDim.label
    };
  });

  console.log('‚úÖ [VALIDATION] Validaci√≥n completada exitosamente');
  console.log('üìä [VALIDATION] Top dimensions:', result.topDimensions.length);

  return result;
}

export async function POST(request: NextRequest) {
  try {
    console.log('üöÄ [ANALYZE API] Iniciando an√°lisis...');
    
    // Cargar configuraci√≥n
    const config = await loadAnalysisConfig();
    
    const { prompt } = await request.json();
    console.log('üìù [ANALYZE API] Prompt length:', prompt?.length);
    
    // Debug de variables de entorno
    console.log('üîç [ANALYZE API] Debugging API Key...');
    console.log('üìä [ANALYZE API] NODE_ENV:', process.env.NODE_ENV);
    console.log('üîë [ANALYZE API] API Key exists:', !!process.env.OPENAI_API_KEY);
    console.log('üîë [ANALYZE API] API Key length:', process.env.OPENAI_API_KEY?.length);
    console.log('üîë [ANALYZE API] API Key starts with:', process.env.OPENAI_API_KEY?.substring(0, 20) + '...');

    // Validar prompt usando configuraci√≥n
    if (!prompt || prompt.length < config.settings.analysis.minPromptLength) {
      console.log('‚ùå [ANALYZE API] Prompt muy corto:', prompt?.length);
      return NextResponse.json(
        { error: `El prompt debe tener al menos ${config.settings.analysis.minPromptLength} caracteres` },
        { status: 400 }
      );
    }

    if (!process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY === 'tu-api-key-aqui') {
      console.log('‚ùå [ANALYZE API] API key no configurada o es placeholder');
      return NextResponse.json(
        { error: 'API key de OpenAI no configurada. Revisa tu archivo .env.local' },
        { status: 500 }
      );
    }

    // Inicializar OpenAI con configuraci√≥n
    console.log('ü§ñ [ANALYZE API] Inicializando cliente OpenAI...');
    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });

    // Construir prompt del sistema desde la configuraci√≥n
    console.log('üìã [ANALYZE API] Construyendo prompt del sistema desde configuraci√≥n...');
    const systemPrompt = config.systemPrompt.content;

    console.log('ü§ñ [ANALYZE API] Enviando prompt a OpenAI...');
    console.log('‚öôÔ∏è [ANALYZE API] Configuraci√≥n:', {
      model: config.settings.openai.model,
      temperature: config.settings.openai.temperature,
      maxTokens: config.settings.openai.maxTokens
    });

    const completion = await openai.chat.completions.create({
      model: config.settings.openai.model,
      messages: [
        {
          role: "system",
          content: systemPrompt
        },
        {
          role: "user",
          content: `Analiza este prompt creativo y responde √öNICAMENTE con el JSON:\n\n"${prompt}"`
        }
      ],
      temperature: config.settings.openai.temperature,
      max_tokens: config.settings.openai.maxTokens,
    });

    console.log('‚úÖ [ANALYZE API] Respuesta recibida de OpenAI');
    console.log('üìä [ANALYZE API] Usage:', completion.usage);
    
    const responseContent = completion.choices[0].message.content;
    console.log('üìù [ANALYZE API] Contenido completo de respuesta:');
    console.log('---START RESPONSE---');
    console.log(responseContent);
    console.log('---END RESPONSE---');
    
    if (!responseContent) {
      console.log('‚ùå [ANALYZE API] Sin contenido en respuesta');
      throw new Error('No se recibi√≥ respuesta de OpenAI');
    }

    // Limpiar respuesta: remover markdown y texto extra
    let cleanedResponse = responseContent.trim();
    
    // Remover bloques de c√≥digo markdown si existen
    if (cleanedResponse.startsWith('```')) {
      const lines = cleanedResponse.split('\n');
      lines.shift(); // Remover primera l√≠nea ```json
      if (lines[lines.length - 1].trim() === '```') {
        lines.pop(); // Remover √∫ltima l√≠nea ```
      }
      cleanedResponse = lines.join('\n').trim();
    }

    console.log('üßπ [ANALYZE API] Respuesta limpiada:');
    console.log('---START CLEANED---');
    console.log(cleanedResponse);
    console.log('---END CLEANED---');

    // Intentar parsear el JSON con mejor manejo de errores
    let analysisResult;
    try {
      analysisResult = JSON.parse(cleanedResponse);
      console.log('‚úÖ [ANALYZE API] JSON parseado exitosamente');
    } catch (parseError: any) {
      console.log('‚ùå [ANALYZE API] Error parseando JSON:', parseError.message);
      console.log('üîç [ANALYZE API] Contenido que fall√≥:', cleanedResponse.substring(0, 200) + '...');
      
      // Intentar extraer JSON de respuesta m√°s compleja
      const jsonMatch = cleanedResponse.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        try {
          analysisResult = JSON.parse(jsonMatch[0]);
          console.log('‚úÖ [ANALYZE API] JSON extra√≠do y parseado exitosamente');
        } catch (secondError) {
          console.log('‚ùå [ANALYZE API] Segundo intento de parsing fall√≥');
          throw new Error(`Respuesta de OpenAI no contiene JSON v√°lido: ${parseError.message}`);
        }
      } else {
        throw new Error(`No se encontr√≥ JSON en la respuesta de OpenAI: ${parseError.message}`);
      }
    }

    // Validar y normalizar resultado usando configuraci√≥n
    const validatedResult = validateAnalysisResult(analysisResult, config);

    console.log('‚úÖ [ANALYZE API] An√°lisis completado exitosamente');

    return NextResponse.json({
      success: true,
      analysis: validatedResult,
      timestamp: new Date().toISOString(),
      config: {
        model: config.settings.openai.model,
        dimensionsCount: config.dimensions.length
      }
    });

  } catch (error: any) {
    console.error('üí• [ANALYZE API] Error completo:', error);
    console.error('üìç [ANALYZE API] Stack trace:', error.stack);
    
    if (error.code === 'insufficient_quota') {
      console.log('üí≥ [ANALYZE API] L√≠mite de cuota alcanzado');
      return NextResponse.json(
        { error: 'L√≠mite de API de OpenAI alcanzado. Intenta m√°s tarde.' },
        { status: 429 }
      );
    }

    if (error.code === 'invalid_api_key') {
      console.log('üîë [ANALYZE API] API key inv√°lida');
      return NextResponse.json(
        { error: 'API key de OpenAI inv√°lida. Verifica tu configuraci√≥n.' },
        { status: 401 }
      );
    }

    if (error.message?.includes('JSON')) {
      console.log('üîß [ANALYZE API] Error de parsing JSON');
      return NextResponse.json(
        { 
          error: 'Error procesando la respuesta de IA. La respuesta no tiene el formato esperado.',
          details: process.env.NODE_ENV === 'development' ? error.message : undefined
        },
        { status: 500 }
      );
    }

    if (error.message?.includes('configuraci√≥n')) {
      console.log('üìã [ANALYZE API] Error de configuraci√≥n');
      return NextResponse.json(
        { 
          error: 'Error en la configuraci√≥n del sistema. Contacta al administrador.',
          details: process.env.NODE_ENV === 'development' ? error.message : undefined
        },
        { status: 500 }
      );
    }

    console.log('üö® [ANALYZE API] Error gen√©rico');
    return NextResponse.json(
      { 
        error: 'Error interno del servidor. Intenta nuevamente.',
        details: process.env.NODE_ENV === 'development' ? error.message : undefined
      },
      { status: 500 }
    );
  }
}

// Exportar funciones para uso en otras rutas API
export { loadAnalysisConfig, validateAnalysisResult };